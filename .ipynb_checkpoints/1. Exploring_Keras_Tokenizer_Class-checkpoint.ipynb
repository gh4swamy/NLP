{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = ['Ram is in eighth grade and ready to go to ninth grade',\n",
    "            'Shanti is in sixth grade']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize and fit the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = Tokenizer(num_words=15) # num_words -> Vocablury size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t.fit_on_texts(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look into Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('ram', 1),\n",
       "             ('is', 2),\n",
       "             ('in', 2),\n",
       "             ('eighth', 1),\n",
       "             ('grade', 3),\n",
       "             ('and', 1),\n",
       "             ('ready', 1),\n",
       "             ('to', 2),\n",
       "             ('go', 1),\n",
       "             ('ninth', 1),\n",
       "             ('shanti', 1),\n",
       "             ('sixth', 1)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_counts  #Each word and how many times they appeared across all docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How come its 'ram' and not 'Ram'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.document_count #Number of documents Tokenizer got fit on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 7,\n",
       " 'eighth': 6,\n",
       " 'go': 9,\n",
       " 'grade': 1,\n",
       " 'in': 3,\n",
       " 'is': 2,\n",
       " 'ninth': 10,\n",
       " 'ram': 5,\n",
       " 'ready': 8,\n",
       " 'shanti': 11,\n",
       " 'sixth': 12,\n",
       " 'to': 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_index #Unique index of each word in Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 1,\n",
       " 'eighth': 1,\n",
       " 'go': 1,\n",
       " 'grade': 2,\n",
       " 'in': 2,\n",
       " 'is': 2,\n",
       " 'ninth': 1,\n",
       " 'ram': 1,\n",
       " 'ready': 1,\n",
       " 'shanti': 1,\n",
       " 'sixth': 1,\n",
       " 'to': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_docs #How many documents a word appeared in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting docs to Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
       "         0.,  0.],\n",
       "       [ 0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,\n",
       "         0.,  0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.texts_to_matrix(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  2.,  1.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
       "         0.,  0.],\n",
       "       [ 0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,\n",
       "         0.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.texts_to_matrix(documents,mode='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.86490296,  0.51082562,  0.51082562,  1.17360019,\n",
       "         0.69314718,  0.69314718,  0.69314718,  0.69314718,  0.69314718,\n",
       "         0.69314718,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.51082562,  0.51082562,  0.51082562,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.69314718,  0.69314718,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.texts_to_matrix(documents,mode='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
